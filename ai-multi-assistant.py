import streamlit as st
from openai import OpenAI
import PyPDF2
import docx
from dotenv import load_dotenv
import os

class MultiAssistant:
    def __init__(self):
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL"),
        )
        self.model = os.getenv("MODEL")

    def process_request(self, system_prompt: str, user_prompt: str) -> str:
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                stream=True,
            )

            result = st.empty()
            collected_chunks = []

            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    collected_chunks.append(chunk.choices[0].delta.content)
                    result.markdown("".join(collected_chunks))

            return "".join(collected_chunks)

        except Exception as e:
            return f"Error: {str(e)}"


class ResearchAssistant:
    def __init__(self) -> None:
        load_dotenv()
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL"),
        )
        self.model = os.getenv("MODEL")

    def extract_text(self, uploaded_file):
        text = ""
        if uploaded_file.type == "application/pdf":
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            for page in pdf_reader.pages:
                text += page.extract_text()
        elif (
            uploaded_file.type
            == "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        ):
            doc = docx.Document(uploaded_file)
            for para in doc.paragraphs:
                text += para.text + "\n"
        else:
            text = str(uploaded_file.read(), "utf-8")
        return text

    def analyze_content(self, text, query):
        prompt = f"""Analyze this text and answer the following query:
            Text: {text[:2000]}...
            Query: {query}
            
            Provide:
            1. Direct answer to the query
            2. Supporting evidence
            3. Key findings
            4. Limitations of the analysis
            """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a research assistant skilled in analyzing academic and technical documents.",
                    },
                    {"role": "user", "content": prompt},
                ],
                stream=True,
            )

            result = st.empty()
            collected_chunks = []

            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    collected_chunks.append(chunk.choices[0].delta.content)
                    result.markdown("".join(collected_chunks))

            return "".join(collected_chunks)

        except Exception as e:
            return f"Error: {str(e)}"


def get_system_prompts():
    return {
        # Code Assistant Prompts
        "Code Generation": """You are an expert Python programmer who writes clean, efficient, and well-documented code.
Follow these guidelines:
1. Start with a brief comment explaining the code's purpose
2. Include docstrings for functions
3. Use clear variable names
4. Add inline comments for complex logic
5. Follow PEP 8 style guidelines
6. Include example usage
7. Handle common edge cases""",
        "Code Explanation": """You are a patient and knowledgeable coding tutor.
Analyze the code and explain:
1. Overall purpose and functionality
2. Break down of each major component
3. Key programming concepts used
4. Flow of execution
5. Important variables and functions
6. Any clever techniques or patterns
7. Potential learning points for students""",
        "Code Review": """You are a senior code reviewer with expertise in Python best practices.
Review the code for:
1. Logical errors or bugs
2. Performance optimization opportunities
3. Security vulnerabilities
4. Code style and PEP 8 compliance
5. Error handling improvements
6. Documentation completeness
7. Code modularity and reusability
8. Memory efficiency""",
        # Language Tutor Prompts
        "Grammar Check": """You are an expert English language teacher.
Review the text for:
1. Grammar errors
2. Punctuation mistakes
3. Sentence structure
4. Word choice improvements
5. Style consistency
Provide clear explanations and corrections.""",
        "Vocabulary Enhancement": """You are a vocabulary expert.
Analyze the text and:
1. Suggest more sophisticated alternatives
2. Explain idioms and phrases
3. Provide context for word usage
4. Suggest synonyms and antonyms
5. Explain connotations""",
        # Document Generator Prompts
        "Business Proposal": """You are a professional business writer.
Generate a proposal that includes:
1. Executive summary
2. Problem statement
3. Proposed solution
4. Timeline and milestones
5. Budget breakdown
6. Risk assessment
7. Expected outcomes""",
        "Professional Email": """You are an expert in business communication.
Create an email that:
1. Has a clear subject line
2. Maintains professional tone
3. Is concise and focused
4. Includes call to action
5. Has appropriate closing
6. Follows email etiquette""",
        # Research Assistant Prompt
        "Document Analysis": """You are a research assistant skilled in analyzing academic and technical documents.
Analyze the text and answer the query.
Provide:
1. Direct answer to the query
2. Supporting evidence
3. Key findings
4. Limitations of the analysis""",
    }


def get_example_prompts():
    return {
        # Code Assistant Examples
        "Code Generation": {
            "placeholder": "ä½¿ç”¨tkinter æ¥åˆ¶ä½œä¸€ä¸ªå›¾å½¢åŒ–çš„è´ªåƒè›‡æ¸¸æˆ",
            "default": "",
        },
        "Code Explanation": {
            "placeholder": "è¯·ç»™æˆ‘ä»£ç ,æˆ‘æ¥å¸®ä½ è§£é‡Š",
            "default": "",
        },
        "Code Review": {"placeholder": "è¯·ç»™æˆ‘ä»£ç ï¼Œæˆ‘æ¥å¸®ä½ å®¡æŸ¥", "default": ""},
        # Language Tutor Examples
        "Grammar Check": {"placeholder": "è¯·è¾“å…¥éœ€è¦è¿›è¡Œè¯­æ³•æ£€æŸ¥çš„æ–‡æœ¬", "default": ""},
        "Vocabulary Enhancement": {
            "placeholder": "è¯·è¾“å…¥éœ€è¦è¿›è¡Œæ›´ä¸“ä¸šè¡¨è¾¾çš„æ–‡æœ¬",
            "default": "",
        },
        # Document Generator Examples
        "Business Proposal": {
            "placeholder": "è¯·æè¿°ä½ çš„å•†ä¸šéœ€æ±‚",
            "default": "",
        },
        "Professional Email": {
            "placeholder": "è¯·è¾“å…¥emailçš„éœ€æ±‚å’Œç›®æ ‡",
            "default": "",
        },
        # Research Assistant Example
        "Document Analysis": {
            "placeholder": "è¾“å…¥æ‚¨å¯¹æ–‡æ¡£çš„æŸ¥è¯¢é—®é¢˜ï¼Œä¾‹å¦‚ï¼šä¸»è¦å‘ç°æ˜¯ä»€ä¹ˆï¼Ÿ",
            "default": "",
        },
    }


def main():
    st.set_page_config(page_title="æ™ºèƒ½åŠ©æ‰‹å°é”", page_icon="ğŸ¤–", layout="wide")
    st.title("ğŸ¤– å¤šåŠŸèƒ½AI")

    # å·¥å…·åˆ†ç±»é…ç½®
    tool_categories = {
        "Code Assistant": ["Code Generation", "Code Explanation", "Code Review"],
        "Language Tutor": ["Grammar Check", "Vocabulary Enhancement"],
        "Document Generator": ["Business Proposal", "Professional Email"],
        "Research Assistant": ["Document Analysis"],
    }

    # ä¾§è¾¹æ 
    st.sidebar.title("å·¥å…·é€‰æ‹©")
    category = st.sidebar.selectbox("å·¥å…·ç±»ç›®", list(tool_categories.keys()))
    mode = st.sidebar.selectbox("å·¥å…·", tool_categories[category])

    # ç³»ç»Ÿæç¤ºè¯å’Œç¤ºä¾‹
    system_prompts = get_system_prompts()
    example_prompts = get_example_prompts()

    # ä¾§è¾¹æ è¯´æ˜
    st.sidebar.markdown("---")
    st.sidebar.markdown(f"**å½“å‰å·¥å…·**: {mode}")
    st.sidebar.markdown("**å·¥å…·æè¿°:**")
    st.sidebar.markdown(system_prompts[mode].replace("\n", "\n\n"))

    # ä¸»å†…å®¹åŒºå¸ƒå±€
    col1, col2 = st.columns([2, 3])

    # å·¦ä¾§è¾“å…¥åŒºåŸŸ
    with col1:
        st.markdown(f"### {mode}è¾“å…¥")

        if category == "Research Assistant":
            uploaded_files = st.file_uploader(
                "ğŸ“ ä¸Šä¼ ç ”ç©¶æ–‡æ¡£ï¼ˆæ”¯æŒPDF/DOCX/TXTï¼‰",
                type=["pdf", "docx", "txt"],
                accept_multiple_files=True,
            )
            user_prompt = st.text_area(
                "â“ è¾“å…¥æŸ¥è¯¢é—®é¢˜",
                height=150,
                placeholder=example_prompts[mode]["placeholder"],
            )
        else:
            user_prompt = st.text_area(
                "ğŸ“ è¾“å…¥å†…å®¹",
                height=300,
                placeholder=example_prompts[mode]["placeholder"],
                value=example_prompts[mode]["default"],
            )

        process_button = st.button(
            "ğŸš€ æ‰§è¡Œå¤„ç†", type="primary", use_container_width=True
        )

    # å³ä¾§è¾“å‡ºåŒºåŸŸ
    with col2:
        st.markdown("### è¾“å‡ºç»“æœ")
        output_container = st.container()

    # å¤„ç†æŒ‰é’®é€»è¾‘
    if process_button:
        if category == "Research Assistant":
            if not uploaded_files:
                st.warning("è¯·å…ˆä¸Šä¼ æ–‡æ¡£æ–‡ä»¶ï¼")
            else:
                with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
                    assistant = ResearchAssistant()
                    with output_container:
                        for file in uploaded_files:
                            with st.expander(f"ğŸ“„ æ–‡æ¡£åˆ†ææŠ¥å‘Š - {file.name}"):
                                text = assistant.extract_text(file)

                                tab1, tab2, tab3 = st.tabs(
                                    ["æ·±åº¦åˆ†æ", "å…³é”®æ‘˜å½•", "å…¨æ–‡æ‘˜è¦"]
                                )
                                with tab1:
                                    assistant.analyze_content(text, user_prompt)
                                with tab2:
                                    assistant.analyze_content(
                                        text, "æå–å…³é”®ç‚¹å’Œæ ¸å¿ƒè®ºæ®"
                                    )
                                with tab3:
                                    assistant.analyze_content(text, "ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦")

                        if len(uploaded_files) > 1:
                            st.subheader("ğŸ“Š è·¨æ–‡æ¡£åˆ†æç»“è®º")
                            st.info("å¤šæ–‡æ¡£äº¤å‰æ¯”å¯¹åŠŸèƒ½å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼")

        else:  # åŸæœ‰å¤„ç†é€»è¾‘
            if user_prompt:
                with st.spinner("å¤„ç†ä¸­..."):
                    assistant = MultiAssistant()
                    with output_container:
                        assistant.process_request(system_prompts[mode], user_prompt)
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹ï¼")

    # é¡µè„š
    st.markdown("---")
    st.markdown(
        '<div style="text-align: center">Made with â¤ï¸ using DeepSeek R1 and Ollama</div>',
        unsafe_allow_html=True,
    )



if __name__ == "__main__":
    main()
